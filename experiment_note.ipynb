{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ViT import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9729, -0.1928,  0.2514]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor = torch.randn(1, 3, 224, 224)\n",
    "vit = ViT(num_classes=3)\n",
    "vit(random_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "ViT (ViT)                                                    [32, 3, 224, 224]    [32, 3]              152,064              True\n",
       "├─PatchEmbedding (patch_embedding)                           [32, 3, 224, 224]    [32, 196, 768]       --                   True\n",
       "│    └─Conv2d (patcher)                                      [32, 3, 224, 224]    [32, 768, 14, 14]    590,592              True\n",
       "│    └─Flatten (flatten)                                     [32, 768, 14, 14]    [32, 768, 196]       --                   --\n",
       "├─Dropout (embedding_dropout)                                [32, 197, 768]       [32, 197, 768]       --                   --\n",
       "├─Sequential (transformer_encoder)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    └─TransformerEncoderBlock (0)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (1)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (2)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (3)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (4)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (5)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (6)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (7)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (8)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (9)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (10)                          [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "│    └─TransformerEncoderBlock (11)                          [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─MultiheadSelfAttentionBock (msa_block)           [32, 197, 768]       [32, 197, 768]       2,363,904            True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 197, 768]       [32, 197, 768]       4,723,968            True\n",
       "├─Sequential (classifier)                                    [32, 768]            [32, 3]              --                   True\n",
       "│    └─LayerNorm (0)                                         [32, 768]            [32, 768]            1,536                True\n",
       "│    └─Linear (1)                                            [32, 768]            [32, 3]              2,307                True\n",
       "============================================================================================================================================\n",
       "Total params: 85,800,963\n",
       "Trainable params: 85,800,963\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.52\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3292.20\n",
       "Params size (MB): 229.20\n",
       "Estimated Total Size (MB): 3540.67\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=vit, input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20, row_settings=[\"var_names\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
